{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание №9\n",
    "### Генерация поэзии с помощью нейронных сетей: шаг 1\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), @neychev\n",
    "\n",
    "Ваша основная задача: научиться генерироват стихи с помощью простой рекуррентной нейронной сети (Vanilla RNN). В качестве корпуса текстов для обучения будет выступать роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import string\n",
    "import os\n",
    "from random import sample\n",
    "\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu device is available\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('{} device is available'.format(device))\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MPenWOy01Ooa",
    "outputId": "a92e8e33-e009-4bd4-ac12-3b1b5e1cd3f2"
   },
   "source": [
    "#### 1. Загрузка данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-18 18:27:17--  https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/onegin.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 262521 (256K) [text/plain]\n",
      "Saving to: ‘onegin.txt.2’\n",
      "\n",
      "onegin.txt.2        100%[===================>] 256,37K   981KB/s    in 0,3s    \n",
      "\n",
      "2023-12-18 18:27:18 (981 KB/s) - ‘onegin.txt.2’ saved [262521/262521]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "!wget https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/onegin.txt\n",
    "    \n",
    "with open('onegin.txt', 'r') as iofile:\n",
    "    text = iofile.readlines()\n",
    "    \n",
    "text = \"\".join([x.replace('\\t\\t', '').lower() for x in text])\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQYpmGfR_gJ8"
   },
   "source": [
    "#### 2. Построение словаря и предобработка текста\n",
    "В данном задании требуется построить языковую модель на уровне символов. Приведем весь текст к нижнему регистру и построим словарь из всех символов в доступном корпусе текстов. Также добавим токен `<sos>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "tokens = sorted(set(text.lower())) + ['<sos>']\n",
    "num_tokens = len(tokens)\n",
    "\n",
    "assert num_tokens == 84, \"Check the tokenization process\"\n",
    "\n",
    "token_to_idx = {x: idx for idx, x in enumerate(tokens)}\n",
    "idx_to_token = {idx: x for idx, x in enumerate(tokens)}\n",
    "\n",
    "assert len(tokens) == len(token_to_idx), \"Mapping should be unique\"\n",
    "\n",
    "print(\"Seems fine!\")\n",
    "\n",
    "\n",
    "text_encoded = [token_to_idx[x] for x in text]\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ваша задача__: обучить классическую рекуррентную нейронную сеть (Vanilla RNN) предсказывать следующий символ на полученном корпусе текстов и сгенерировать последовательность длины 100 для фиксированной начальной фразы.\n",
    "\n",
    "Вы можете воспользоваться кодом с занятие №6 или же обратиться к следующим ссылкам:\n",
    "* Замечательная статья за авторством Andrej Karpathy об использовании RNN: [link](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "* Пример char-rnn от Andrej Karpathy: [github repo](https://github.com/karpathy/char-rnn)\n",
    "* Замечательный пример генерации поэзии Шекспира: [github repo](https://github.com/spro/practical-pytorch/blob/master/char-rnn-generation/char-rnn-generation.ipynb)\n",
    "\n",
    "Данное задание является достаточно творческим. Не страшно, если поначалу оно вызывает затруднения. Последняя ссылка в списке выше может быть особенно полезна в данном случае.\n",
    "\n",
    "Далее для вашего удобства реализована функция, которая генерирует случайный батч размера `batch_size` из строк длиной `seq_length`. Вы можете использовать его при обучении модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "batch_size = 256\n",
    "seq_length = 100\n",
    "start_column = np.zeros((batch_size, 1), dtype=int) + token_to_idx['<sos>']\n",
    "\n",
    "def generate_chunk():\n",
    "    global text_encoded, start_column, batch_size, seq_length\n",
    "\n",
    "    start_index = np.random.randint(0, len(text_encoded) - batch_size*seq_length - 1)\n",
    "    data = np.array(text_encoded[start_index:start_index + batch_size*seq_length]).reshape((batch_size, -1))\n",
    "    yield np.hstack((start_column, data))\n",
    "# __________end of block__________    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример батча:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83, 53, 52, ..., 50,  5,  0],\n",
       "       [83, 49, 61, ..., 59, 63,  1],\n",
       "       [83, 64, 51, ..., 66,  5,  0],\n",
       "       ...,\n",
       "       [83, 58, 53, ..., 50, 61, 50],\n",
       "       [83, 49,  1, ..., 59, 69, 56],\n",
       "       [83, 72, 66, ..., 38,  0,  0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(generate_chunk())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее вам предстоит написать код для обучения модели и генерации текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "PAD_IDX = token_to_idx['<sos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '(': 3,\n",
       " ')': 4,\n",
       " ',': 5,\n",
       " '-': 6,\n",
       " '.': 7,\n",
       " '5': 8,\n",
       " '7': 9,\n",
       " '8': 10,\n",
       " '9': 11,\n",
       " ':': 12,\n",
       " ';': 13,\n",
       " '?': 14,\n",
       " '[': 15,\n",
       " ']': 16,\n",
       " '^': 17,\n",
       " 'a': 18,\n",
       " 'b': 19,\n",
       " 'c': 20,\n",
       " 'd': 21,\n",
       " 'e': 22,\n",
       " 'f': 23,\n",
       " 'g': 24,\n",
       " 'h': 25,\n",
       " 'i': 26,\n",
       " 'k': 27,\n",
       " 'l': 28,\n",
       " 'm': 29,\n",
       " 'n': 30,\n",
       " 'o': 31,\n",
       " 'p': 32,\n",
       " 'q': 33,\n",
       " 'r': 34,\n",
       " 's': 35,\n",
       " 't': 36,\n",
       " 'u': 37,\n",
       " 'v': 38,\n",
       " 'w': 39,\n",
       " 'x': 40,\n",
       " 'y': 41,\n",
       " 'z': 42,\n",
       " '«': 43,\n",
       " '»': 44,\n",
       " 'а': 45,\n",
       " 'б': 46,\n",
       " 'в': 47,\n",
       " 'г': 48,\n",
       " 'д': 49,\n",
       " 'е': 50,\n",
       " 'ж': 51,\n",
       " 'з': 52,\n",
       " 'и': 53,\n",
       " 'й': 54,\n",
       " 'к': 55,\n",
       " 'л': 56,\n",
       " 'м': 57,\n",
       " 'н': 58,\n",
       " 'о': 59,\n",
       " 'п': 60,\n",
       " 'р': 61,\n",
       " 'с': 62,\n",
       " 'т': 63,\n",
       " 'у': 64,\n",
       " 'ф': 65,\n",
       " 'х': 66,\n",
       " 'ц': 67,\n",
       " 'ч': 68,\n",
       " 'ш': 69,\n",
       " 'щ': 70,\n",
       " 'ъ': 71,\n",
       " 'ы': 72,\n",
       " 'ь': 73,\n",
       " 'э': 74,\n",
       " 'ю': 75,\n",
       " 'я': 76,\n",
       " 'ё': 77,\n",
       " '–': 78,\n",
       " '—': 79,\n",
       " '’': 80,\n",
       " '…': 81,\n",
       " '€': 82,\n",
       " '<sos>': 83}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перевод токена в буквы\n",
    "def word_from_tokens(tokens: str) -> np.array:\n",
    "     return np.array([token_to_idx[token] for token in tokens])\n",
    "\n",
    "# Перевод уже в предложения \n",
    "def sentectence_to_tokens(batch: typing.List[str]) -> np.array:\n",
    "    return np.concatenate(list(map(word_from_tokens, batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сводим (сжимаем/растягиваем) к единому размеру\n",
    "def shape_text(text: typing.List[str], max_tokens_len: int):\n",
    "    joined_text = \" \".join(text)\n",
    "    n_tokens = len(joined_text) // max_tokens_len\n",
    "    reshaped_text = []\n",
    "    for i in range(0, n_tokens * max_tokens_len, max_tokens_len):\n",
    "        reshaped_text.append(joined_text[i:i+max_tokens_len])\n",
    "    return reshaped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переводим предложения в матрицы для RNN\n",
    "def to_matrix(text: typing.List[str], max_len: int=None, pad: int=PAD_IDX, dtype: str='int32', batch_first: bool=True):\n",
    "    size = max_len or max(map(len, text))\n",
    "    matrix = np.zeros([len(text), size], dtype) + pad\n",
    "    for i in range(len(text)):\n",
    "        line_ix = sentectence_to_tokens([text[i]])\n",
    "        matrix[i, :len(line_ix)] = line_ix\n",
    "    if not batch_first:\n",
    "        matrix = np.transpose(matrix)\n",
    "    return torch.tensor(matrix, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Из семинара\n",
    "class VanillaCharRNN(nn.Module):\n",
    "   \n",
    "    def __init__(\n",
    "        self,\n",
    "        num_tokens: int=len(tokens),\n",
    "        embedding_size: int=64,\n",
    "        rnn_num_units: int=128\n",
    "    ):\n",
    "        super(VanillaCharRNN, self).__init__()\n",
    "        self.rnn_num_units = rnn_num_units\n",
    "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
    "        self.rnn = nn.RNN(embedding_size, rnn_num_units, batch_first=True)\n",
    "        self.linear = nn.Linear(rnn_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        x_emb = self.embedding(x)\n",
    "        out, h_next = self.rnn(x_emb, h_prev)\n",
    "        logits = self.linear(out)\n",
    "        return h_next, logits\n",
    "    \n",
    "    def initial_state(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.rnn_num_units, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import seaborn as sns\n",
    "sns.set_theme(style='darkgrid')\n",
    "\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, num_tokens=num_tokens, emb_size=16, hidden_size=128):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
    "        self.rnn = nn.RNN(emb_size, hidden_size, batch_first=True,\n",
    "                         nonlinearity='relu')\n",
    "        self.hid_to_logits = nn.Linear(hidden_size, num_tokens)\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        assert isinstance(x.data, torch.LongTensor)\n",
    "        out, hid_state = self.rnn(self.emb(x))\n",
    "        next_logits = self.hid_to_logits(out)\n",
    "        next_logp = F.log_softmax(next_logits, dim=-1)\n",
    "        return next_logp\n",
    "    \n",
    "    def generate(self, x, hid_state):\n",
    "        out, hid_state = self.rnn(self.emb(x), hid_state)\n",
    "        next_logits = self.hid_to_logits(out)\n",
    "        return next_logits, hid_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mMultiStepLR(optimizer, \n\u001b[1;32m     11\u001b[0m                                 milestones\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1500\u001b[39m, \u001b[38;5;241m2500\u001b[39m], gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3500\u001b[39m):\n\u001b[0;32m---> 14\u001b[0m     batch_ix \u001b[38;5;241m=\u001b[39m \u001b[43mto_matrix\u001b[49m(sample(quatrains, \u001b[38;5;241m16\u001b[39m), max_len\u001b[38;5;241m=\u001b[39mMAX_LENGTH)\n\u001b[1;32m     15\u001b[0m     batch_ix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(batch_ix, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m     17\u001b[0m     logp_seq \u001b[38;5;241m=\u001b[39m model(batch_ix)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'to_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass \n",
    "\n",
    "model = CharRNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "                                milestones=[1500, 2500], gamma=0.1)\n",
    "\n",
    "for i in range(3500):\n",
    "    batch_ix = to_matrix(sample(quatrains, 16), max_len=MAX_LENGTH)\n",
    "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "    \n",
    "    logp_seq = model(batch_ix)\n",
    "\n",
    "    loss = F.nll_loss(logp_seq[:, :-1].contiguous().view(-1, num_tokens), \n",
    "                  batch_ix[:, 1:].contiguous().view(-1), \n",
    "                      ignore_index=token_to_idx['_'])\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    loss_history.append(loss.data.numpy())\n",
    "    if (i+1)%100 == 0:\n",
    "        plt.figure(figsize=(10,8))\n",
    "        clear_output(True)\n",
    "        plt.plot(loss_history, lw=2, label='loss')\n",
    "        plt.xticks(fontsize=16)\n",
    "        plt.yticks(fontsize=16)\n",
    "        plt.legend(shadow=True, fontsize=18)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_epoch(model, hidden_state, all_batches, batch_size):\n",
    "    global PAD_IDX\n",
    "    n_batches = all_batches.shape[0] // batch_size\n",
    "    loss = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for i in range(0, n_batches * batch_size, batch_size):\n",
    "        batch_ix = all_batches[i:i+batch_size]\n",
    "        hidden_state, out = model(batch_ix, hidden_state)\n",
    "        actual_next_tokens = batch_ix[:, 1:]\n",
    "\n",
    "        batch_loss = loss(out[:, :-1].reshape(-1, len(tokens)), actual_next_tokens.reshape(-1))\n",
    "        batch_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        epoch_loss += batch_loss.item()\n",
    "        hidden_state.detach_()\n",
    "        hidden_state = hidden_state.detach()\n",
    "\n",
    "    epoch_loss /= n_batches\n",
    "    return hidden_state, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, n_epochs: int=16, optimizer=None, max_tokens_len: int=200-3, batch_size: int=10):\n",
    "    losses = []\n",
    "    # Привели к единому размеру\n",
    "    shaped_text = shape_text(text, max_tokens_len)\n",
    "    # Перевели в матрицу\n",
    "    all_batches = to_matrix(shaped_text, max_tokens_len)\n",
    "    # Поехали\n",
    "    state = model.initial_state(batch_size)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"{}-st epoch of {}\".format(epoch + 1, n_epochs))\n",
    "        state, epoch_loss = rnn_epoch(model, state, all_batches, batch_size)\n",
    "        losses.append(epoch_loss)\n",
    "\n",
    "    return losses, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-st epoch of 512\n",
      "2-st epoch of 512\n",
      "3-st epoch of 512\n",
      "4-st epoch of 512\n",
      "5-st epoch of 512\n",
      "6-st epoch of 512\n",
      "7-st epoch of 512\n",
      "8-st epoch of 512\n",
      "9-st epoch of 512\n",
      "10-st epoch of 512\n",
      "11-st epoch of 512\n",
      "12-st epoch of 512\n",
      "13-st epoch of 512\n",
      "14-st epoch of 512\n",
      "15-st epoch of 512\n",
      "16-st epoch of 512\n",
      "17-st epoch of 512\n",
      "18-st epoch of 512\n",
      "19-st epoch of 512\n",
      "20-st epoch of 512\n",
      "21-st epoch of 512\n",
      "22-st epoch of 512\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[1;32m      3\u001b[0m N_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n\u001b[0;32m----> 4\u001b[0m vanilla_losses, vanilla_state \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[50], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, n_epochs, optimizer, max_tokens_len, batch_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-st epoch of \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, n_epochs))\n\u001b[0;32m---> 12\u001b[0m     state, epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mrnn_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(epoch_loss)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m losses, state\n",
      "Cell \u001b[0;32mIn[49], line 9\u001b[0m, in \u001b[0;36mrnn_epoch\u001b[0;34m(model, hidden_state, all_batches, batch_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, n_batches \u001b[38;5;241m*\u001b[39m batch_size, batch_size):\n\u001b[1;32m      8\u001b[0m     batch_ix \u001b[38;5;241m=\u001b[39m all_batches[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m----> 9\u001b[0m     hidden_state, out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_ix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     actual_next_tokens \u001b[38;5;241m=\u001b[39m batch_ix[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     12\u001b[0m     batch_loss \u001b[38;5;241m=\u001b[39m loss(out[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(tokens)), actual_next_tokens\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[48], line 18\u001b[0m, in \u001b[0;36mVanillaCharRNN.forward\u001b[0;34m(self, x, h_prev)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, h_prev):\n\u001b[1;32m     17\u001b[0m     x_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[0;32m---> 18\u001b[0m     out, h_next \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_prev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(out)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m h_next, logits\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:471\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRNN_TANH\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 471\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn_tanh\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    475\u001b[0m         result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mrnn_relu(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    476\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m    477\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = VanillaCharRNN()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "N_EPOCHS = 512\n",
    "vanilla_losses, vanilla_state = train(model, N_EPOCHS, optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве иллюстрации ниже доступен график значений функции потерь, построенный в ходе обучения авторской сети (сам код для ее обучения вам и предстоит написать)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шаблон функции `generate_sample` также доступен ниже. Вы можете как дозаполнить его, так и написать свою собственную функцию с нуля. Не забывайте, что все примеры в обучающей выборке начинались с токена `<sos>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(model, seed_phrase=' ', max_length=400, temperature=1.0):\n",
    "    x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
    "    x_sequence = torch.tensor([[x_sequence]], dtype=torch.long)\n",
    "    states = model.initial_state(batch_size=1)\n",
    "    \n",
    "    for i in range(len(seed_phrase) - 1):\n",
    "        states, _ = model(x_sequence[:, :, i], states)\n",
    "\n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        states, out = model(x_sequence[:,:, -1], states)\n",
    "        p_next = F.softmax(out / temperature, dim=-1).data.numpy()[0].ravel()\n",
    "        \n",
    "        next_ix = np.random.choice(len(tokens), p=p_next)\n",
    "        next_ix = torch.tensor([[[next_ix]]], dtype=torch.long)\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=2)\n",
    "    return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in [0.2, 0.5, 1.0,]:\n",
    "    print(f\"\\n\\tTemperature: {t}\")\n",
    "    print(generate_sample(model, seed_phrase=\" мой дядя самых честных правил\", temperature=t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример текста сгенерированного обученной моделью доступен ниже. Не страшно, что в тексте много несуществующих слов. Используемая модель очень проста: это простая классическая RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сдача задания\n",
    "Сгенерируйте десять последовательностей длиной 500, используя строку ' мой дядя самых честных правил'. Температуру для генерации выберите самостоятельно на основании визуального качества генериуремого текста. Не забудьте удалить все технические токены в случае их наличия.\n",
    "\n",
    "Сгенерированную последовательность сохрание в переменную `generated_phrase` и сдайте сгенерированный ниже файл в контест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_phrase = ' мой дядя самых честных правил'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generated_phrases = # your code here\n",
    "\n",
    "# For example:\n",
    "\n",
    "generated_phrases = [\n",
    "    generate_sample(\n",
    "        model,\n",
    "        ' мой дядя самых честных правил',\n",
    "        max_length=500,\n",
    "        temperature=1.\n",
    "    ).replace('<sos>', '')\n",
    "    for _ in range(10)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "import json\n",
    "if 'generated_phrases' not in locals():\n",
    "    raise ValueError(\"Please, save generated phrases to `generated_phrases` variable\")\n",
    "\n",
    "for phrase in generated_phrases:\n",
    "\n",
    "    if not isinstance(phrase, str):\n",
    "        raise ValueError(\"The generated phrase should be a string\")\n",
    "\n",
    "    if len(phrase) != 500:\n",
    "        raise ValueError(\"The `generated_phrase` length should be equal to 500\")\n",
    "\n",
    "    assert all([x in set(tokens) for x in set(list(phrase))]), 'Unknown tokens detected, check your submission!'\n",
    "    \n",
    "\n",
    "submission_dict = {\n",
    "    'token_to_idx': token_to_idx,\n",
    "    'generated_phrases': generated_phrases\n",
    "}\n",
    "\n",
    "with open('submission_dict.json', 'w') as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print('File saved to `submission_dict.json`')\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "NLP HW Lab01_Poetry_generation.v5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
